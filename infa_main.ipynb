{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostume222/inf-test/blob/master/infa_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 0.** If for some reason you encounter issues navigating the folders in the project or having errors you can delete the project folder in the online colab environment by using the following code cell. If you are just starting to use this fresh colab notebook skip this step."
      ],
      "metadata": {
        "id": "BQrhkeZQ9fPi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srSx4UMl03T7",
        "outputId": "e0c74c43-2630-4b4d-f1dd-6e0aa6f58fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "sample_data\n",
            "rm: cannot remove 'inf-test/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cd ~\n",
        "!pwd\n",
        "!ls\n",
        "!rm -r inf-test/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1.** Clone github repository from link https://github.com/mostume222/inf-test.git , this will download the source code and also make the correct project structure to tun the compression program."
      ],
      "metadata": {
        "id": "wyYoNtFd6C7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mostume222/inf-test.git\n",
        "%cd inf-test\n",
        "!git checkout master #go to master branch to have the correct project structure\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdpWnTzL7pry",
        "outputId": "16c38405-eefb-43a7-b730-6ae15941de79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'inf-test'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 164 (delta 64), reused 111 (delta 31), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (164/164), 37.69 MiB | 6.18 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content/inf-test\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n",
            "Switched to a new branch 'master'\n",
            "data  env  infa_main.ipynb  output_compression\tREADME.md  sequences  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2.** Install the conda environment in /inf-test/env/infa.yml to install dependencies neded to run the compression procedure.\n",
        "\n",
        "If you would like to install your own dependencies, the important ones are:\n",
        "\n",
        "* cd-hit 4.8.1  \n",
        "* bowtie2 2.5.4\n",
        "* cutadapt 3.5\n",
        "* python 3.6.13\n",
        "* perl 5.34.0\n",
        "* pip 21.2.2"
      ],
      "metadata": {
        "id": "DKL6oR9e7hd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install condacolab\n",
        "!ls\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!ls\n",
        "#create conda envionment in infa.yml file\n",
        "!conda env create -f env/infa.yml --quiet\n",
        "!conda env list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7_JSSoG71Bn",
        "outputId": "c68f1d5e-4dc9-4f2d-b9a8-a9a4651fd478"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  env  infa_main.ipynb  output_compression\tREADME.md  sequences  src\n",
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:12\n",
            "ðŸ” Restarting kernel...\n",
            "condacolab_install.log\tdata  env  infa_main.ipynb  output_compression\tREADME.md  sequences  src\n",
            "Channels:\n",
            " - defaults\n",
            " - conda-forge\n",
            " - bioconda\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "# conda environments:\n",
            "#\n",
            "base                     /usr/local\n",
            "infc                     /usr/local/envs/infc\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3.** Run the following cell to run the compression procedure to generate the pangenome sequences of the input sequence."
      ],
      "metadata": {
        "id": "2L709NnCU9zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload your own file\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "destination_dir = '/content/inf-test/sequences/'\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded file to the destination directory\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, os.path.join(destination_dir, filename))\n",
        "\n",
        "print(f\"File(s) successfully moved to {destination_dir}\")\n"
      ],
      "metadata": {
        "id": "7fdIoOOnPbF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  run the script with conda env\n",
        "%cd /content/inf-test/src/compressor/\n",
        "!source activate infc && ls\n",
        "!chmod +x run_compress.sh\n",
        "!source activate infc && ./run_compress.sh 0.94 0.958 200 50 100000 1,.comp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-UX_O9wP-Tm",
        "outputId": "bf989f59-d80c-4d6a-f421-2f3971120550"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/inf-test/src/compressor\n",
            "cluster_acc_family.pl\t    divider.pl\t\t       lucas_compressor.sh\n",
            "cluster_acc.pl\t\t    enumerate.pl\t       modify_headers.pl\n",
            "cluster_acc_variant.pl\t    enumerate.py\t       remove.sh\n",
            "cluster_element_counter.pl  enumerate.sh\t       run_compress.sh\n",
            "concat_clusters.sh\t    kmer.pl\t\t       uniques_concatenation.pl\n",
            "concat_clusters_test.sh     label_clusters_variant.sh  uniques_entanglement.pl\n",
            "counter.pl\t\t    lucas_back\t\t       uniques_gitrog.pl\n",
            "count_lenghts_pieces.pl     lucas_compressor_b.sh      uniques_intanglement.pl\n",
            "1,.comp\n",
            "This is cutadapt 3.5 with Python 3.6.13\n",
            "Command line parameters: --max-n 0 -o /content/inf-test/src/compressor/../..//output_compression/1,.comp//kmers_clean.fasta /content/inf-test/src/compressor/../..//output_compression/1,.comp//kmers_w.fasta\n",
            "Processing reads on 1 core in single-end mode ...\n",
            "Done           00:00:02       405,046 reads @   6.4 Âµs/read;   9.41 M reads/minute\n",
            "Finished in 2.58 s (6 us/read; 9.41 M reads/minute).\n",
            "\n",
            "=== Summary ===\n",
            "\n",
            "Total reads processed:                 405,046\n",
            "\n",
            "== Read fate breakdown ==\n",
            "Reads with too many N:                     840 (0.2%)\n",
            "Reads written (passing filters):       404,206 (99.8%)\n",
            "\n",
            "Total basepairs processed:    81,009,138 bp\n",
            "Total written (filtered):     80,841,138 bp (99.8%)\n",
            "================================================================\n",
            "Program: CD-HIT, V4.8.1 (+OpenMP), Apr 11 2024, 11:47:57\n",
            "Command: cd-hit -i\n",
            "         /content/inf-test/src/compressor/../..//output_compression/1,.comp//kmers_clean.fasta\n",
            "         -o\n",
            "         /content/inf-test/src/compressor/../..//output_compression/1,.comp//result\n",
            "         -c 0.94 -n 5 -M 8000 -T 8 -G 1 -g 1 -sc 1 -aS 0.958\n",
            "\n",
            "Started: Tue Aug 27 04:48:40 2024\n",
            "================================================================\n",
            "                            Output                              \n",
            "----------------------------------------------------------------\n",
            "Warning: total number of CPUs in the system is 2\n",
            "Actual number of CPUs to be used: 2\n",
            "\n",
            "total seq: 404206\n",
            "longest and shortest : 200 and 199\n",
            "Total letters: 80841138\n",
            "Sequences have been sorted\n",
            "\n",
            "Approximated minimal memory consumption:\n",
            "Sequence        : 130M\n",
            "Buffer          : 2 X 20M = 41M\n",
            "Table           : 2 X 71M = 143M\n",
            "Miscellaneous   : 5M\n",
            "Total           : 320M\n",
            "\n",
            "Table limit with the given memory limit:\n",
            "Max number of representatives: 4000000\n",
            "Max number of word counting entries: 959914394\n",
            "\n",
            "# comparing sequences from          0  to     101051\n",
            "..........    10000  finished       1965  clusters\n",
            "..........    20000  finished       3058  clusters\n",
            "..........    30000  finished       3794  clusters\n",
            "..........    40000  finished       4512  clusters\n",
            "..........    50000  finished       5238  clusters\n",
            "..........    60000  finished       6130  clusters\n",
            "..........    70000  finished       6598  clusters\n",
            "..........    80000  finished       7016  clusters\n",
            "..........    90000  finished       7715  clusters\n",
            "..........   100000  finished       8097  clusters\n",
            ".---------- new table with     8115 representatives\n",
            "# comparing sequences from     101051  to     176839\n",
            "..........   110000  finished       8508  clusters\n",
            "..........   120000  finished       9205  clusters\n",
            "..........   130000  finished       9494  clusters\n",
            "..........   140000  finished       9981  clusters\n",
            "..........   150000  finished      10508  clusters\n",
            "..........   160000  finished      11125  clusters\n",
            "..........   170000  finished      11474  clusters\n",
            "100.0%---------- new table with     3418 representatives\n",
            "# comparing sequences from     176839  to     233680\n",
            "..........   180000  finished      11718  clusters\n",
            "..........   190000  finished      12248  clusters\n",
            "..........   200000  finished      12718  clusters\n",
            "..........   210000  finished      13348  clusters\n",
            "..........   220000  finished      13554  clusters\n",
            "..........   230000  finished      14089  clusters\n",
            "99.9%---------- new table with     2690 representatives\n",
            "# comparing sequences from     233680  to     276311\n",
            "..........   240000  finished      14751  clusters\n",
            "..........   250000  finished      15172  clusters\n",
            "..........   260000  finished      15701  clusters\n",
            "..........   270000  finished      16337  clusters\n",
            "99.9%---------- new table with     2833 representatives\n",
            "# comparing sequences from     276311  to     308284\n",
            "..........   280000  finished      17257  clusters\n",
            "..........   290000  finished      17818  clusters\n",
            "..........   300000  finished      18464  clusters\n",
            "100.0%---------- new table with     2066 representatives\n",
            "# comparing sequences from     308284  to     332264\n",
            "..........   310000  finished      19167  clusters\n",
            "..........   320000  finished      19778  clusters\n",
            "..........   330000  finished      20397  clusters\n",
            "99.9%---------- new table with     1334 representatives\n",
            "# comparing sequences from     332264  to     350249\n",
            "..........   340000  finished      21013  clusters\n",
            "..........   350000  finished      21318  clusters\n",
            "99.9%---------- new table with      863 representatives\n",
            "# comparing sequences from     350249  to     363738\n",
            "..........   360000  finished      21847  clusters\n",
            "100.0%---------- new table with      610 representatives\n",
            "# comparing sequences from     363738  to     373855\n",
            "..........   370000  finished      22214  clusters\n",
            "99.9%---------- new table with      528 representatives\n",
            "# comparing sequences from     373855  to     381442\n",
            "..........   380000  finished      23197  clusters\n",
            "100.0%---------- new table with      782 representatives\n",
            "# comparing sequences from     381442  to     387133\n",
            "100.0%---------- new table with      272 representatives\n",
            "# comparing sequences from     387133  to     391401\n",
            "..........   390000  finished      23565  clusters\n",
            "99.9%---------- new table with      163 representatives\n",
            "# comparing sequences from     391401  to     394602\n",
            "100.0%---------- new table with      186 representatives\n",
            "# comparing sequences from     394602  to     397003\n",
            "99.9%---------- new table with       56 representatives\n",
            "# comparing sequences from     397003  to     398803\n",
            "99.9%---------- new table with      123 representatives\n",
            "# comparing sequences from     398803  to     400153\n",
            "..........   400000  finished      24185  clusters\n",
            "100.0%---------- new table with      147 representatives\n",
            "# comparing sequences from     400153  to     401166\n",
            "99.9%---------- new table with       14 representatives\n",
            "# comparing sequences from     401166  to     401926\n",
            "----------    114 remaining sequences to the next cycle\n",
            "---------- new table with      132 representatives\n",
            "# comparing sequences from     401812  to     402410\n",
            "99.9%---------- new table with        2 representatives\n",
            "# comparing sequences from     402410  to     402859\n",
            "99.9%---------- new table with       28 representatives\n",
            "# comparing sequences from     402859  to     403195\n",
            "99.9%---------- new table with       19 representatives\n",
            "# comparing sequences from     403195  to     403447\n",
            "100.0%---------- new table with       11 representatives\n",
            "# comparing sequences from     403447  to     404206\n",
            "....................---------- new table with       10 representatives\n",
            "\n",
            "   404206  finished      24402  clusters\n",
            "\n",
            "Approximated maximum memory consumption: 336M\n",
            "writing new database\n",
            "writing clustering information\n",
            "program completed !\n",
            "\n",
            "Total CPU time 1531.57\n",
            "finished accessions and number\n",
            "finished accessions and variants\n",
            "325678\n",
            "finished making coors file\n",
            "finish hashing the cdhit output24402\n",
            " lenght of the order array 24402\n",
            "finished walking the kmers_order 24402\n",
            "finish hashing the coors filefinish hashing the cluste sizes24402\n",
            "finished hashing the taxids of each genome9811\n",
            "dis\n",
            "gitrog fed\n",
            "finishing the hashing of the databases9811\n",
            "end of the concatenation script\n",
            "end of concatenation pipeline\\n\n",
            "segment >>>1,.comp\n",
            "1,.comp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean\n",
        "!rm -r /content/inf-test/output_compression/1,.comp/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfdC7b_9QUP8",
        "outputId": "d5a0eb87-cac0-4ae2-e33e-59ad00016a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/inf-test/output_compression/1,.comp/': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}