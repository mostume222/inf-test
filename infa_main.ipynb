{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostume222/inf-test/blob/master/infa_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 0.** If for some reason you encounter issues navigating the folders in the project or having errors you can delete the project folder in the online colab environment by using the following code cell. If you are just starting to use this fresh colab notebook skip this step."
      ],
      "metadata": {
        "id": "BQrhkeZQ9fPi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srSx4UMl03T7",
        "outputId": "e0c74c43-2630-4b4d-f1dd-6e0aa6f58fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "sample_data\n",
            "rm: cannot remove 'inf-test/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cd ~\n",
        "!pwd\n",
        "!ls\n",
        "!rm -r inf-test/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1.** Clone github repository from link https://github.com/mostume222/inf-test.git , this will download the source code and also make the correct project structure to tun the compression program."
      ],
      "metadata": {
        "id": "wyYoNtFd6C7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mostume222/inf-test.git\n",
        "%cd inf-test\n",
        "!git checkout master #go to master branch to have the correct project structure\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdpWnTzL7pry",
        "outputId": "55da1ef1-4601-4306-9567-4d678f6d512a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'inf-test'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 174 (delta 69), reused 113 (delta 31), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (174/174), 37.70 MiB | 3.98 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "/content/inf-test\n",
            "Updating files: 100% (34/34), done.\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n",
            "Switched to a new branch 'master'\n",
            "data  env  infa_main.ipynb  output_compression\tREADME.md  sequences  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2.** Install the conda environment in /inf-test/env/infa.yml to install dependencies neded to run the compression procedure.\n",
        "\n",
        "If you would like to install your own dependencies, the important ones are:\n",
        "\n",
        "* cd-hit 4.8.1  \n",
        "* bowtie2 2.5.4\n",
        "* cutadapt 3.5\n",
        "* python 3.6.13\n",
        "* perl 5.34.0\n",
        "* pip 21.2.2"
      ],
      "metadata": {
        "id": "DKL6oR9e7hd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install condacolab\n",
        "!ls\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!ls\n",
        "#create conda envionment in infa.yml file\n",
        "!conda env create -f env/infa.yml --quiet\n",
        "!conda env list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7_JSSoG71Bn",
        "outputId": "7aab636d-c968-467c-e887-0d1bdddc62ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  env  infa_main.ipynb  output_compression\tREADME.md  sequences  src\n",
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:12\n",
            "üîÅ Restarting kernel...\n",
            "condacolab_install.log\tdata  env  infa_main.ipynb  output_compression\tREADME.md  sequences  src\n",
            "Channels:\n",
            " - defaults\n",
            " - conda-forge\n",
            " - bioconda\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "# conda environments:\n",
            "#\n",
            "base                     /usr/local\n",
            "infc                     /usr/local/envs/infc\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3.** Run the following cell to run the compression procedure to generate the pangenome sequences of the input sequence."
      ],
      "metadata": {
        "id": "2L709NnCU9zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload your own file\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "destination_dir = '/content/inf-test/sequences/'\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded file to the destination directory\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, os.path.join(destination_dir, filename))\n",
        "\n",
        "print(f\"File(s) successfully moved to {destination_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "7fdIoOOnPbF7",
        "outputId": "2fdc5811-1ee6-44db-a112-82fdfb321202"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-abf94c57-69f7-4ec6-ac34-21c30e056d90\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-abf94c57-69f7-4ec6-ac34-21c30e056d90\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2,.comp to 2,.comp\n",
            "File(s) successfully moved to /content/inf-test/sequences/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  run the script with conda env\n",
        "%cd /content/inf-test/src/compressor/\n",
        "!source activate infc && ls\n",
        "!chmod +x run_compress.sh\n",
        "!source activate infc && ./run_compress.sh 0.94 0.958 200 50 100000 2,.comp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-UX_O9wP-Tm",
        "outputId": "5aa581fa-e29d-454b-ba68-b58a748ce422"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/inf-test/src/compressor\n",
            "cluster_acc_family.pl\t    divider.pl\t\t       lucas_compressor.sh\n",
            "cluster_acc.pl\t\t    enumerate.pl\t       modify_headers.pl\n",
            "cluster_acc_variant.pl\t    enumerate.py\t       remove.sh\n",
            "cluster_element_counter.pl  enumerate.sh\t       run_compress.sh\n",
            "concat_clusters.sh\t    kmer.pl\t\t       uniques_concatenation.pl\n",
            "concat_clusters_test.sh     label_clusters_variant.sh  uniques_entanglement.pl\n",
            "counter.pl\t\t    lucas_back\t\t       uniques_gitrog.pl\n",
            "count_lenghts_pieces.pl     lucas_compressor_b.sh      uniques_intanglement.pl\n",
            "2,.comp\n",
            "This is cutadapt 3.5 with Python 3.6.13\n",
            "Command line parameters: --max-n 0 -o /content/inf-test/src/compressor/../..//output_compression/2,.comp//kmers_clean.fasta /content/inf-test/src/compressor/../..//output_compression/2,.comp//kmers_w.fasta\n",
            "Processing reads on 1 core in single-end mode ...\n",
            "Done           00:00:03       405,046 reads @   9.7 ¬µs/read;   6.19 M reads/minute\n",
            "Finished in 3.93 s (10 us/read; 6.18 M reads/minute).\n",
            "\n",
            "=== Summary ===\n",
            "\n",
            "Total reads processed:                 405,046\n",
            "\n",
            "== Read fate breakdown ==\n",
            "Reads with too many N:                     840 (0.2%)\n",
            "Reads written (passing filters):       404,206 (99.8%)\n",
            "\n",
            "Total basepairs processed:    81,009,138 bp\n",
            "Total written (filtered):     80,841,138 bp (99.8%)\n",
            "================================================================\n",
            "Program: CD-HIT, V4.8.1 (+OpenMP), Apr 11 2024, 11:47:57\n",
            "Command: cd-hit -i\n",
            "         /content/inf-test/src/compressor/../..//output_compression/2,.comp//kmers_clean.fasta\n",
            "         -o\n",
            "         /content/inf-test/src/compressor/../..//output_compression/2,.comp//result\n",
            "         -c 0.94 -n 5 -M 8000 -T 8 -G 1 -g 1 -sc 1 -aS 0.958\n",
            "\n",
            "Started: Tue Aug 27 05:22:01 2024\n",
            "================================================================\n",
            "                            Output                              \n",
            "----------------------------------------------------------------\n",
            "Warning: total number of CPUs in the system is 2\n",
            "Actual number of CPUs to be used: 2\n",
            "\n",
            "total seq: 404206\n",
            "longest and shortest : 200 and 199\n",
            "Total letters: 80841138\n",
            "Sequences have been sorted\n",
            "\n",
            "Approximated minimal memory consumption:\n",
            "Sequence        : 130M\n",
            "Buffer          : 2 X 20M = 41M\n",
            "Table           : 2 X 71M = 143M\n",
            "Miscellaneous   : 5M\n",
            "Total           : 320M\n",
            "\n",
            "Table limit with the given memory limit:\n",
            "Max number of representatives: 4000000\n",
            "Max number of word counting entries: 959914394\n",
            "\n",
            "# comparing sequences from          0  to     101051\n",
            "..........    10000  finished       1965  clusters\n",
            "..........    20000  finished       3058  clusters\n",
            "..........    30000  finished       3794  clusters\n",
            "..........    40000  finished       4512  clusters\n",
            "..........    50000  finished       5238  clusters\n",
            "..........    60000  finished       6130  clusters\n",
            "..........    70000  finished       6598  clusters\n",
            "..........    80000  finished       7016  clusters\n",
            "..........    90000  finished       7715  clusters\n",
            "..........   100000  finished       8097  clusters\n",
            ".---------- new table with     8115 representatives\n",
            "# comparing sequences from     101051  to     176839\n",
            "..........   110000  finished       8508  clusters\n",
            "..........   120000  finished       9205  clusters\n",
            "..........   130000  finished       9494  clusters\n",
            "..........   140000  finished       9981  clusters\n",
            "..........   150000  finished      10508  clusters\n",
            "..........   160000  finished      11125  clusters\n",
            "..........   170000  finished      11474  clusters\n",
            "99.9%---------- new table with     3418 representatives\n",
            "# comparing sequences from     176839  to     233680\n",
            "..........   180000  finished      11718  clusters\n",
            "..........   190000  finished      12248  clusters\n",
            "..........   200000  finished      12718  clusters\n",
            "..........   210000  finished      13348  clusters\n",
            "..........   220000  finished      13554  clusters\n",
            "..........   230000  finished      14089  clusters\n",
            "99.9%---------- new table with     2690 representatives\n",
            "# comparing sequences from     233680  to     276311\n",
            "..........   240000  finished      14751  clusters\n",
            "..........   250000  finished      15172  clusters\n",
            "..........   260000  finished      15701  clusters\n",
            "..........   270000  finished      16337  clusters\n",
            "99.9%---------- new table with     2833 representatives\n",
            "# comparing sequences from     276311  to     308284\n",
            "..........   280000  finished      17257  clusters\n",
            "..........   290000  finished      17818  clusters\n",
            "..........   300000  finished      18464  clusters\n",
            "100.0%---------- new table with     2066 representatives\n",
            "# comparing sequences from     308284  to     332264\n",
            "..........   310000  finished      19167  clusters\n",
            "..........   320000  finished      19778  clusters\n",
            "..........   330000  finished      20397  clusters\n",
            "100.0%---------- new table with     1334 representatives\n",
            "# comparing sequences from     332264  to     350249\n",
            "..........   340000  finished      21013  clusters\n",
            "..........   350000  finished      21318  clusters\n",
            "100.0%---------- new table with      863 representatives\n",
            "# comparing sequences from     350249  to     363738\n",
            "..........   360000  finished      21847  clusters\n",
            "100.0%---------- new table with      610 representatives\n",
            "# comparing sequences from     363738  to     373855\n",
            "..........   370000  finished      22214  clusters\n",
            "100.0%---------- new table with      528 representatives\n",
            "# comparing sequences from     373855  to     381442\n",
            "..........   380000  finished      23197  clusters\n",
            "99.9%---------- new table with      782 representatives\n",
            "# comparing sequences from     381442  to     387133\n",
            "100.0%---------- new table with      272 representatives\n",
            "# comparing sequences from     387133  to     391401\n",
            "..........   390000  finished      23565  clusters\n",
            "99.9%---------- new table with      163 representatives\n",
            "# comparing sequences from     391401  to     394602\n",
            "100.0%---------- new table with      186 representatives\n",
            "# comparing sequences from     394602  to     397003\n",
            "99.9%---------- new table with       56 representatives\n",
            "# comparing sequences from     397003  to     398803\n",
            "99.9%---------- new table with      123 representatives\n",
            "# comparing sequences from     398803  to     400153\n",
            "..........   400000  finished      24185  clusters\n",
            "100.0%---------- new table with      147 representatives\n",
            "# comparing sequences from     400153  to     401166\n",
            "100.0%---------- new table with       14 representatives\n",
            "# comparing sequences from     401166  to     401926\n",
            "----------    125 remaining sequences to the next cycle\n",
            "---------- new table with      132 representatives\n",
            "# comparing sequences from     401801  to     402402\n",
            "100.0%---------- new table with        2 representatives\n",
            "# comparing sequences from     402402  to     402853\n",
            "99.9%---------- new table with       26 representatives\n",
            "# comparing sequences from     402853  to     403191\n",
            "99.9%---------- new table with       21 representatives\n",
            "# comparing sequences from     403191  to     403444\n",
            "99.9%---------- new table with       11 representatives\n",
            "# comparing sequences from     403444  to     404206\n",
            ".....................---------- new table with       10 representatives\n",
            "\n",
            "   404206  finished      24402  clusters\n",
            "\n",
            "Approximated maximum memory consumption: 336M\n",
            "writing new database\n",
            "writing clustering information\n",
            "program completed !\n",
            "\n",
            "Total CPU time 1548.91\n",
            "finished accessions and number\n",
            "finished accessions and variants\n",
            "325678\n",
            "finished making coors file\n",
            "finish hashing the cdhit output24402\n",
            " lenght of the order array 24402\n",
            "finished walking the kmers_order 24402\n",
            "finish hashing the coors filefinish hashing the cluste sizes24402\n",
            "finished hashing the taxids of each genome9811\n",
            "dis\n",
            "gitrog fed\n",
            "finishing the hashing of the databases9811\n",
            "end of the concatenation script\n",
            "end of concatenation pipeline\\n\n",
            "segment >>>2,.comp\n",
            "2,.comp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean\n",
        "!rm -r /content/inf-test/output_compression/1,.comp/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfdC7b_9QUP8",
        "outputId": "d5a0eb87-cac0-4ae2-e33e-59ad00016a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/inf-test/output_compression/1,.comp/': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}