{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usjunco/pangen/blob/master/infa_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 0.** If for some reason you encounter issues navigating the folders in the project or having errors, you can delete the project folder in the online colab environment by using the following code cell. If you are just starting to use this fresh colab notebook skip this step.\n",
        "\n",
        "You can also go to the \"Runtime\" option and select \"Disconnect and delete runtime\"."
      ],
      "metadata": {
        "id": "BQrhkeZQ9fPi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srSx4UMl03T7",
        "outputId": "ae2765d4-072a-4f08-80a5-0f6b5e6ad841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "inf-test  sample_data\n"
          ]
        }
      ],
      "source": [
        "!cd ~\n",
        "!pwd\n",
        "!ls\n",
        "!rm -r pangen/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1.** Clone the github repository from https://github.com/usjunco/pangen.git , this will download the source code and also make the correct project structure to run the compression program."
      ],
      "metadata": {
        "id": "wyYoNtFd6C7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/usjunco/pangen\n",
        "%cd pangen\n",
        "!git checkout master #go to master branch to have the correct project structure\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdpWnTzL7pry",
        "outputId": "87ae1b4c-56b8-4167-bc54-a93a57fb96d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pangen'...\n",
            "remote: Enumerating objects: 567, done.\u001b[K\n",
            "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
            "remote: Total 567 (delta 101), reused 111 (delta 38), pack-reused 353 (from 1)\u001b[K\n",
            "Receiving objects: 100% (567/567), 59.83 MiB | 7.39 MiB/s, done.\n",
            "Resolving deltas: 100% (213/213), done.\n",
            "Updating files: 100% (85/85), done.\n",
            "/content/pangen\n",
            "Already on 'master'\n",
            "Your branch is up to date with 'origin/master'.\n",
            "bkp   env     infa_main.ipynb  output\t\t   README.md  sample_input  src\n",
            "data  graphs  input\t       output_compression  run_local  sequences     test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2.** Install the conda environment in /pangen/env/infa.yml to install dependencies needed to run the compression procedure.\n",
        "\n",
        "If you would like to install the dependencies on your own, the important ones are:\n",
        "\n",
        "* cd-hit 4.8.1  \n",
        "* bowtie2 2.5.4\n",
        "* cutadapt 3.5\n",
        "* python 3.6.13\n",
        "* perl 5.34.0\n",
        "* pip 21.2.2"
      ],
      "metadata": {
        "id": "DKL6oR9e7hd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install condacolab\n",
        "!ls\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!ls\n",
        "#create conda envionment in infa.yml file\n",
        "!conda env create -f env/infa.yml --quiet\n",
        "!conda env list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7_JSSoG71Bn",
        "outputId": "a3ad475c-cc48-4a88-f9c3-4aa4e9d10d43"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bkp   env     infa_main.ipynb  output\t\t   README.md  sample_input  src\n",
            "data  graphs  input\t       output_compression  run_local  sequences     test\n",
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:11\n",
            "üîÅ Restarting kernel...\n",
            "bkp\t\t\tenv\t\t input\t\t     README.md\t   sequences\n",
            "condacolab_install.log\tgraphs\t\t output\t\t     run_local\t   src\n",
            "data\t\t\tinfa_main.ipynb  output_compression  sample_input  test\n",
            "Channels:\n",
            " - defaults\n",
            " - conda-forge\n",
            " - bioconda\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "# conda environments:\n",
            "#\n",
            "base                     /usr/local\n",
            "infc                     /usr/local/envs/infc\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3.** Run the following cell to create the function to upload your sequences into the compression procedure."
      ],
      "metadata": {
        "id": "2L709NnCU9zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import file upload dependencies\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def input():\n",
        "  destination_dir = '/content/pangen/input/'\n",
        "  os.makedirs(destination_dir, exist_ok=True)\n",
        "  uploaded = files.upload()\n",
        "  ## move the uploaded file to input directory\n",
        "  for filename in uploaded.keys():\n",
        "      destination = os.path.join(destination_dir, filename)\n",
        "      shutil.move(filename, destination)\n",
        "      filename_nf = destination.split('.')[0]\n",
        "      shutil.move(destination, filename_nf)\n",
        "  ## set and return input name\n",
        "  name_list = filename_nf.split(\"/\")\n",
        "  input_fasta = name_list[-1]\n",
        "  return input_fasta"
      ],
      "metadata": {
        "id": "udpYJPyN8Mio"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4**. Upload your fasta file running the following cell and clicking the \"Choose Files\" button, this file should be in fasta format. (https://www.ncbi.nlm.nih.gov/genbank/fastaformat/) an example of this file can be found in /pangen/sample_input/testsample.fasta/"
      ],
      "metadata": {
        "id": "ruo0Drj2QfXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### this cell is to create the input directory and reciebe the fasta file\n",
        "## import files dependences\n",
        "input_fasta = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ynKNo6y02adF",
        "outputId": "fd3aab1d-aee5-4980-c6b9-fd2cb0e06683"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7c99844f-61a6-4a28-8d96-496b966dc583\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7c99844f-61a6-4a28-8d96-496b966dc583\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving testsample.fasta to testsample.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5**. Upload your classes file, this file must be in a text base format, column wise separated by a \"\\t\" caracter, where the first column is the \"accession id\" of each sequence in the input fasta file, the second column has to be the \"class id\" realted to the refered sequence. An example of this file is in /inf-test/sample_input/classes.dmp/"
      ],
      "metadata": {
        "id": "DDjpivekRUjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_classes = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "uoFQbDgh8sA9",
        "outputId": "67d37c30-0fec-4934-b51a-66d970ddac48"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d04da60b-df24-4375-94a7-a76d796bc7bf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d04da60b-df24-4375-94a7-a76d796bc7bf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving classes.dmp to classes.dmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6**. Upload your names file, this file has the names for all \"class id\" raws in the classes file. This file must be in a text file tab (\"\\t\") separated, the first column being \"class id\", the second column being \"class name\". This format facilitates the making of the final pangenome file and makes it easier to use. An example of this file can be found in /inf-test/sample/release_examples/names.dmp/"
      ],
      "metadata": {
        "id": "BGPNhoYpgnJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "EmT6iUl88qEo",
        "outputId": "1e89e076-aef7-4ece-dadf-d3eb8c0eb59a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aac6eb25-427d-4e92-8a94-5c720fcb4734\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aac6eb25-427d-4e92-8a94-5c720fcb4734\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving names.dmp to names.dmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## download the new merge.pl file\n",
        "%cd /content/pangen/src/\n",
        "!rm /content/pangen/src/merge.pl\n",
        "!curl -O https://raw.githubusercontent.com/usjunco/pangen/master/src/merge.pl\n",
        "print(input_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJvyuo63e4du",
        "outputId": "df813883-5a5b-4feb-d674-2a9f23bafdf3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pangen/src\n",
            "curl: /usr/local/lib/libcurl.so.4: no version information available (required by curl)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1052  100  1052    0     0   5037      0 --:--:-- --:--:-- --:--:--  5033\n",
            "names\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7.** Run the following cell to take the 3 input files and process them into the correct folders. This procedure will generate the necesary requisites to run the compression algorithm correctly."
      ],
      "metadata": {
        "id": "8RFSvfScy_qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## merge the data and put the files in the correct order\n",
        "#  run the script with conda env\n",
        "destination_dir = '/content/pangen/input/'\n",
        "%cd /content/pangen/src/\n",
        "ifld = destination_dir\n",
        "dfld = \"/content/pangen/data/\"\n",
        "os.makedirs(dfld, exist_ok=True)\n",
        "sfld = \"/content/pangen/sequences/\"\n",
        "os.makedirs(sfld, exist_ok=True)\n",
        "!source activate infc && ls\n",
        "!chmod +x merge.pl\n",
        "#!source activate infc && ls {ifld}/{input_fasta}\n",
        "!source activate infc && perl merge.pl {ifld}/{input_fasta} {ifld}/{input_classes} {ifld}/{input_names} {sfld}/{input_fasta}  {dfld}/sci_names.dmp {dfld}/acc_variants.list\n"
      ],
      "metadata": {
        "id": "CK0jWJxl2jUk",
        "outputId": "1386c580-c6fb-440c-e768-21b88e7c9bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pangen/src\n",
            "compressor  merge.pl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8.** Run the coompression algorithm with the follwing cell.\n",
        "The results of the compression can be found in /pangen/output_compression/name_of_your_input/\n",
        "\n",
        "///// you will need to change the names\n",
        "///// of the final files ***italicized text***\n",
        "\"report.dmp\" is the compression report, with general statistics about the compression procedure.\n",
        "\n",
        "\"your_file.pan\" is the pangenome file, this file includes all dispensable and unique pieces for all classes defined in the classes file (second input).\n",
        "\n",
        "Inside the \"pangenome_unique\" folder you can find separated fasta files with the \".u\" extension. This files contains the unique pieces for each class that take part into the compression procedure.\n",
        "\n",
        "**Make the headers descripcion of the pangenome file.**"
      ],
      "metadata": {
        "id": "JQ69AwAE1GDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  run the script with conda env\n",
        "%cd /content/pangen/src/compressor/\n",
        "!source activate infc && ls\n",
        "!chmod +x run_compress.sh\n",
        "!source activate infc && ./run_compress.sh 0.94 0.958 200 50 100000 {input_fasta}\n"
      ],
      "metadata": {
        "id": "6-UX_O9wP-Tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d498f021-36ee-4139-ad23-e3d851699a1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pangen/src/compressor\n",
            "cluster_acc_family.pl\t    divider.pl\t\t       lucas_compressor.sh\n",
            "cluster_acc.pl\t\t    enumerate.pl\t       modify_headers.pl\n",
            "cluster_acc_variant.pl\t    enumerate.py\t       remove.sh\n",
            "cluster_element_counter.pl  enumerate.sh\t       run_compress.sh\n",
            "concat_clusters.sh\t    kmer.pl\t\t       uniques_concatenation.pl\n",
            "concat_clusters_test.sh     label_clusters_variant.sh  uniques_entanglement.pl\n",
            "counter.pl\t\t    lucas_back\t\t       uniques_gitrog.pl\n",
            "count_lenghts_pieces.pl     lucas_compressor_b.sh      uniques_intanglement.pl\n",
            "This is cutadapt 3.5 with Python 3.6.13\n",
            "Command line parameters: --max-n 0 -o /content/pangen/src/compressor/../..//output_compression//testsample//kmers_clean.fasta /content/pangen/src/compressor/../..//output_compression//testsample//kmers_w.fasta\n",
            "Processing reads on 1 core in single-end mode ...\n",
            "Done           00:00:03       404,984 reads @   9.0 ¬µs/read;   6.68 M reads/minute\n",
            "Finished in 3.64 s (9 us/read; 6.68 M reads/minute).\n",
            "\n",
            "=== Summary ===\n",
            "\n",
            "Total reads processed:                 404,984\n",
            "\n",
            "== Read fate breakdown ==\n",
            "Reads with too many N:                     840 (0.2%)\n",
            "Reads written (passing filters):       404,144 (99.8%)\n",
            "\n",
            "Total basepairs processed:    80,996,800 bp\n",
            "Total written (filtered):     80,828,800 bp (99.8%)\n",
            "================================================================\n",
            "Program: CD-HIT, V4.8.1 (+OpenMP), Apr 11 2024, 11:47:57\n",
            "Command: cd-hit -i\n",
            "         /content/pangen/src/compressor/../..//output_compression//testsample//kmers_clean.fasta\n",
            "         -o\n",
            "         /content/pangen/src/compressor/../..//output_compression//testsample//result\n",
            "         -c 0.94 -n 5 -M 8000 -T 8 -G 1 -g 1 -sc 1 -aS 0.958\n",
            "\n",
            "Started: Wed Oct  9 04:14:39 2024\n",
            "================================================================\n",
            "                            Output                              \n",
            "----------------------------------------------------------------\n",
            "Warning: total number of CPUs in the system is 2\n",
            "Actual number of CPUs to be used: 2\n",
            "\n",
            "total seq: 404144\n",
            "longest and shortest : 200 and 200\n",
            "Total letters: 80828800\n",
            "Sequences have been sorted\n",
            "\n",
            "Approximated minimal memory consumption:\n",
            "Sequence        : 129M\n",
            "Buffer          : 2 X 20M = 41M\n",
            "Table           : 2 X 71M = 143M\n",
            "Miscellaneous   : 5M\n",
            "Total           : 320M\n",
            "\n",
            "Table limit with the given memory limit:\n",
            "Max number of representatives: 4000000\n",
            "Max number of word counting entries: 959917347\n",
            "\n",
            "# comparing sequences from          0  to     101036\n",
            "..........    10000  finished       1965  clusters\n",
            "..........    20000  finished       3058  clusters\n",
            "..........    30000  finished       3794  clusters\n",
            "..........    40000  finished       4512  clusters\n",
            "..........    50000  finished       5238  clusters\n",
            "..........    60000  finished       6130  clusters\n",
            "..........    70000  finished       6598  clusters\n",
            "..........    80000  finished       7016  clusters\n",
            "..........    90000  finished       7715  clusters\n",
            "..........   100000  finished       8097  clusters\n",
            ".---------- new table with     8115 representatives\n",
            "# comparing sequences from     101036  to     176813\n",
            "..........   110000  finished       8508  clusters\n",
            "..........   120000  finished       9205  clusters\n",
            "..........   130000  finished       9494  clusters\n",
            "..........   140000  finished       9981  clusters\n",
            "..........   150000  finished      10508  clusters\n",
            "..........   160000  finished      11125  clusters\n",
            "..........   170000  finished      11474  clusters\n",
            "100.0%---------- new table with     3418 representatives\n",
            "# comparing sequences from     176813  to     233645\n",
            "..........   180000  finished      11718  clusters\n",
            "..........   190000  finished      12248  clusters\n",
            "..........   200000  finished      12718  clusters\n",
            "..........   210000  finished      13348  clusters\n",
            "..........   220000  finished      13554  clusters\n",
            "..........   230000  finished      14089  clusters\n",
            "100.0%---------- new table with     2690 representatives\n",
            "# comparing sequences from     233645  to     276269\n",
            "..........   240000  finished      14751  clusters\n",
            "..........   250000  finished      15172  clusters\n",
            "..........   260000  finished      15701  clusters\n",
            "..........   270000  finished      16337  clusters\n",
            "100.0%---------- new table with     2833 representatives\n",
            "# comparing sequences from     276269  to     308237\n",
            "..........   280000  finished      17257  clusters\n",
            "..........   290000  finished      17818  clusters\n",
            "..........   300000  finished      18464  clusters\n",
            "100.0%---------- new table with     2066 representatives\n",
            "# comparing sequences from     308237  to     332213\n",
            "..........   310000  finished      19167  clusters\n",
            "..........   320000  finished      19778  clusters\n",
            "..........   330000  finished      20397  clusters\n",
            "99.9%---------- new table with     1334 representatives\n",
            "# comparing sequences from     332213  to     350195\n",
            "..........   340000  finished      21013  clusters\n",
            "..........   350000  finished      21318  clusters\n",
            "100.0%---------- new table with      863 representatives\n",
            "# comparing sequences from     350195  to     363682\n",
            "..........   360000  finished      21847  clusters\n",
            "100.0%---------- new table with      610 representatives\n",
            "# comparing sequences from     363682  to     373797\n",
            "..........   370000  finished      22214  clusters\n",
            "99.9%---------- new table with      522 representatives\n",
            "# comparing sequences from     373797  to     381383\n",
            "..........   380000  finished      23197  clusters\n",
            "99.9%---------- new table with      787 representatives\n",
            "# comparing sequences from     381383  to     387073\n",
            "100.0%---------- new table with      272 representatives\n",
            "# comparing sequences from     387073  to     391340\n",
            "..........   390000  finished      23565  clusters\n",
            "99.9%---------- new table with      160 representatives\n",
            "# comparing sequences from     391340  to     394541\n",
            "100.0%---------- new table with      190 representatives\n",
            "# comparing sequences from     394541  to     396941\n",
            "99.9%---------- new table with       51 representatives\n",
            "# comparing sequences from     396941  to     398741\n",
            "100.0%---------- new table with      125 representatives\n",
            "# comparing sequences from     398741  to     400091\n",
            "..........   400000  finished      24185  clusters\n",
            "100.0%---------- new table with      150 representatives\n",
            "# comparing sequences from     400091  to     401104\n",
            "99.9%---------- new table with       12 representatives\n",
            "# comparing sequences from     401104  to     401864\n",
            "----------    102 remaining sequences to the next cycle\n",
            "---------- new table with      131 representatives\n",
            "# comparing sequences from     401762  to     402357\n",
            "100.0%---------- new table with        5 representatives\n",
            "# comparing sequences from     402357  to     402803\n",
            "100.0%---------- new table with       14 representatives\n",
            "# comparing sequences from     402803  to     403138\n",
            "99.9%---------- new table with       28 representatives\n",
            "# comparing sequences from     403138  to     403389\n",
            "100.0%---------- new table with       16 representatives\n",
            "# comparing sequences from     403389  to     404144\n",
            ".....................---------- new table with       10 representatives\n",
            "\n",
            "   404144  finished      24402  clusters\n",
            "\n",
            "Approximated maximum memory consumption: 336M\n",
            "writing new database\n",
            "writing clustering information\n",
            "program completed !\n",
            "\n",
            "Total CPU time 1531.93\n",
            "***** \tcompression finished\t*****\n",
            "***** \tprocessing report \t*****\n",
            "filename : testsample\n",
            "nucleotide before compression : 21962041\n",
            "nucleotide after comppression : 2618250\n",
            "compression ratio\t\t: 0.880783\n",
            "initial sequences count : 9811\n"
          ]
        }
      ]
    }
  ]
}